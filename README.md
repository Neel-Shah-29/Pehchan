# Project Pehchan

### Problem Statement
In the ever-evolving metaverse, the need for digitising text documents and
extracting their essential data is becoming more crucial. However, the quality of
these documents can often be poor, resulting in low-quality Optical Character
Recognition (OCR) data and poor document intelligence extraction.

### Our Solution
- > We decided to assess the quality of the documents and determine if they are
fit to undergo OCR and further processing using computer vision, image
processing methods, and machine learning models, or any other solution
that provides the best outcome.
- > Image can vary in size, colour, format, and quality.
- > We will classify the documents into three categories: GOOD,
MODERATE, and POOR, based on the accuracy of OCR text (including
numbers and special characters) 
- > Document quality classes are defined as:
  - GOOD - >= 95% accuracy
  - MODERATE - 88 to 95%
  - POOR - below 88%
  
### Our model
- > It can successfully distinguish different categories of image
- > Model Accuracy is 85%
- > Average Proccessing time is nearly 0.6s
  
### ğŸ‘¨â€ğŸ’»Team Members
- [Kunal Agarwal](https://github.com/KunalA18)
- [Neel Shah](https://github.com/Neel-Shah-29)
- [Chaitya Vora](https://github.com/vorachaitya)
- [Harshil Shah](https://github.com/harshilshah99)

